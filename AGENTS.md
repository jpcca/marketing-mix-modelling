# Project Context for AI Agents

## Overview

This is a **Bayesian Marketing Mix Modeling** research project implementing a mixture of Hill saturation functions to capture heterogeneous consumer response patterns. The project accompanies an academic paper proposing this novel approach.

**Package name:** `hill-mixture-mmm`  
**Core innovation:** Mixture of Hill curves to model latent consumer segments with different response characteristics

## Technology Stack

| Technology | Purpose |
|------------|----------|
| **NumPyro** (≥0.15.0) | Probabilistic programming for Bayesian model definition |
| **JAX** (≥0.4.30) | Accelerated numerical computing (GPU/TPU support) |
| **ArviZ** (≥0.18.0) | Bayesian model evaluation (LOO-CV, WAIC, diagnostics) |
| **Pandas/NumPy** | Data manipulation |
| **Matplotlib/daft-pgm** | Visualization and graphical model diagrams |
| **pytest** | Testing framework |

**Python version:** ≥3.11  
**Build system:** Hatchling (via `uv`)

## Directory Structure

| Directory | Purpose |
|-----------|---------|
| `hill_mmm/` | Main Python package (models, transforms, inference, metrics, benchmarking) |
| `tests/` | Pytest test suite (unit, integration, visualization tests) |
| `paper/` | Git submodule with research paper (LaTeX, figures, bibliography) |
| `scripts/` | Executable scripts (benchmark CLI, notebook conversions) |
| `data/` | Dataset files and data dictionary |
| `docs/` | Research documentation and literature review |
| `results/` | Experiment outputs (CSVs, summary markdown) |

## Key Source Files (`hill_mmm/`)

| File | Role |
|------|------|
| `models.py` | Three NumPyro models: `model_single_hill` (baseline), `model_hill_mixture` (K fixed components), `model_hill_mixture_sparse` (automatic K selection) |
| `transforms.py` | Core math: `adstock_geometric()` (carryover decay), `hill()` / `hill_matrix()` (saturation) |
| `data.py` | Synthetic data generation with 4 DGP scenarios: single, mixture_k2, mixture_k3, mixture_k5 |
| `inference.py` | MCMC utilities: `run_inference()`, `compute_predictions()`, `compute_loo()`, `compute_waic()` |
| `metrics.py` | Evaluation: `compute_effective_k()`, `compute_parameter_recovery()`, `compute_delta_loo()` |
| `benchmark.py` | Experimental runner: `run_benchmark_suite()`, `summarize_benchmark()` |

## Testing

```bash
# All tests (includes slow MCMC runs)
pytest tests/

# Fast unit tests only
pytest tests/ -m "not slow"
```

**Test files:**
- `test_transforms.py` - Unit tests for mathematical transforms
- `test_parameter_recovery.py` - Integration tests verifying MCMC recovers known parameters (slow)
- `test_visualization.py` - Generates publication figures to `paper/figures/`

## Paper Submodule

The `paper/` directory is a git submodule linked to a separate repository.

**Mapping paper sections to code:**
| Paper Section | Implementation |
|---------------|----------------|
| Model Specification (§2) | `hill_mmm/models.py` |
| Data Generation (§3) | `hill_mmm/data.py` |
| Experiments | `hill_mmm/benchmark.py`, `results/` |

**Figures** are auto-generated by `tests/test_visualization.py` into `paper/figures/`.

## Development Workflow

1. **Install dependencies:** `uv sync` or `pip install -e .`
2. **Run tests:** `pytest tests/`
3. **Run benchmarks:** `python scripts/run_benchmarks.py [--quick] [--dgp DGP_NAME]`
4. **Generate paper figures:** `pytest tests/test_visualization.py`
5. **Update paper submodule:** After generating figures, commit in `paper/` then update submodule reference

## Agent Guidance

### When modifying models
- Models are in `hill_mmm/models.py` using NumPyro syntax
- Each model follows pattern: priors → transforms → likelihood
- Run `pytest tests/test_parameter_recovery.py` to verify inference still works

### When modifying transforms
- Core math in `hill_mmm/transforms.py`
- Unit tests in `tests/test_transforms.py` cover edge cases
- These are JAX-compatible functions (no Python loops in hot paths)

### When updating visualizations
- Figure generation code in `tests/test_visualization.py`
- Output goes to `paper/figures/`
- After generating, update paper submodule: commit in `paper/`, then commit submodule reference in main repo

### Running experiments
- Full benchmark suite: `python scripts/run_benchmarks.py`
- Quick mode for testing: `--quick` flag
- Results saved to `results/` directory
